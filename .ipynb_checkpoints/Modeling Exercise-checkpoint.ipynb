{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bb7c4c-452a-408f-ac26-b184f1e10862",
   "metadata": {},
   "source": [
    "# Modeling exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbae80-7f28-4596-945e-a0784e384e4c",
   "metadata": {},
   "source": [
    "## General Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5650156-42a5-4fb7-b74a-dec08bafd6c1",
   "metadata": {},
   "source": [
    "* Submission date: 4.5.2023\n",
    "* Submission Method: Link to your solution notebook in [this sheet](https://docs.google.com/spreadsheets/d/1GNPESGIhJpPb7LwMAyjF5qpJfZQak_mLkE3i5Y7a_VA/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5b684-0d89-4cb5-999e-6a6f5ceeaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e136158-e12c-4d15-9c47-3cd726054a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../src')\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53824c3-ccb9-4f1b-9420-bb0b57509862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0716a6-a156-49a2-83d2-24d5ef36af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import make_circles_dataframe, make_moons_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513df470-6d24-4611-9fe8-61c25397763a",
   "metadata": {},
   "source": [
    "## Fitting and Overfiting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e502f-4b12-4bf1-a981-7135b36e0830",
   "metadata": {},
   "source": [
    "The goal of the following exercise is to:\n",
    "* Observe overfitting due to insuffient data\n",
    "* Observe Overfitting due to overly complex model\n",
    "* Identify the overfitting point by looking at Train vs Test error dynamic\n",
    "* Observe how noise levels effect the needed data samples and model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b1cdc-fcfb-4ac7-841c-a5a534d569cd",
   "metadata": {},
   "source": [
    "To do so, you'll code an experiment in the first part, and analyze the experiment result in the second part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f343cc-0b25-4302-ab24-fc290c07b6ee",
   "metadata": {},
   "source": [
    "### Building an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a17e0-fb6f-479c-98bb-e5a6fc81e1ad",
   "metadata": {},
   "source": [
    "datasetCode:\n",
    "\n",
    "1. Create data of size N with noise level of magnitude NL from datasets DS_NAME. \n",
    "1. Split it to training and validation data (no need for test set), use 80%-20%. \n",
    "1. Use Logistic regression and Choose one complex model of your choice: [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), [SVM with RBF kernel](https://scikit-learn.org/stable/modules/svm.html) with different `gamma` values or [Random forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) with differnt number of `min_samples_split`. \n",
    "1. Train on the train set for different hyper parameter values. compute:\n",
    "   1. Classification accuracy on the training set (TRE)\n",
    "   1. Classification accuracy on the validation set (TESTE)\n",
    "   1. The difference beteen the two above (E_DIFF)\n",
    "1. Save DS_NAME, N, NL, CLF_NAME, K, TRE, TESTE, E_DIFF and the regularization/hyper param (K, gamma or min_samples_split and regularization value for the linear regression classifier)\n",
    "\n",
    "Repeat for:\n",
    "* DS_NAME in Moons, Circles\n",
    "* N (number of samples) in [5, 10, 50, 100, 1000, 10000]\n",
    "* NL (noise level) in [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "* For the complex model: 10 Values of hyper parameter of the complex model you've chosen.\n",
    "* For the linear model: 5 values of ridge (l2) regularization - [0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e0146-9c7a-4cf1-a83e-da9a11bcc796",
   "metadata": {},
   "source": [
    "### Analysing the expermient results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39e9c4-0332-4564-a674-52b99332ecfd",
   "metadata": {},
   "source": [
    "1. For SVM only, For dataset of size 10k and for each dataset, What are the best model params? How stable is it? \n",
    "1. For SVM only, For dataset of size 10k and for each dataset, What is the most stable model and model params? How good is it in comparison to other models? Explain using bias and variance terminoligy.\n",
    "1. Does regularization help for linear models? consider different datasets sizes. \n",
    "1. For a given noise level of your chioce, How does the train, test and difference error changes with increasing data sizes? (answer for svm and LR seperatly)\n",
    "1. For a given noise level of your chioce, How does the train, test and difference error changes with increasing model complexity? (answer for svm and LR seperatly)\n",
    "1. Are the noise level effect the number of datapoints needed to reach optimal test results? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237fa350-4106-419c-9020-51986a0a716d",
   "metadata": {},
   "source": [
    "Bonus:\n",
    "\n",
    "* For SVM: Select one dataset and with 0.2 noise level. Identify the optimal model params, and visualize the decision boundry learned. \n",
    "  * Hint: Use a grid. See classification models notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf7262-12b1-4417-acd2-eb8365b04b11",
   "metadata": {},
   "source": [
    "## Tips and Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4522e-a8e9-4476-90ac-d1a2679085f4",
   "metadata": {},
   "source": [
    "For buliding the experiment:\n",
    "\n",
    "* Start with one dataframe holding all the data for both datastes with different noise level. Use the `make_<dataset_name>_dataframe()` functions below, and add two columns, dataset_name and noise_level, before appending the new dataset to the rest of the datasets. Use `df = pd.DataFrame()` to start with an empty dataframe and using a loop, add data to it using `df = df.append(<the needed df here>)`. Verify that you have 10k samples for each dataset type and noise level by a proper `.value_counts()`. You can modify the \n",
    "* When you'll need an N samples data with a specific noise level, use `query()` and `head(n)` to get the needed dataset. \n",
    "* Use sklearn `train_test_split()` method to split the data with `test_size` and `random_state` parameters set correctly to ensure you are always splitting the data the same why for a given fold `k`. Read [the docs](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) if needed. \n",
    "* You can also not create your own data splitter, and instead use `model_selection.cross_validate()` from sklearn. You'll need to ask for the train erros as well as the test errors, see [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html).\n",
    "* Use prints in proper location to ensure the progress of the experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f130c6-62ba-4490-983d-1d63470dc615",
   "metadata": {},
   "source": [
    "**If you get stuck, and need refernce, scroll to the end of the notebook to see more hints!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ffe8f-8c0b-4dc3-9cc2-9c3dc02852d7",
   "metadata": {},
   "source": [
    "## Moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b4c61-454e-4887-963f-61d5ec6bc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons,make_circles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392ae8f-32a7-4c77-a5be-34043ecd09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "moons_df = make_moons_dataframe(n_samples=1000, noise_level=0.1)\n",
    "moons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4d95c-3cad-4596-a8b3-29d67aa9859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact\n",
    "def plot_noisy_moons(noise_level = widgets.FloatSlider(value=0, min=0, max=0.5, step=0.05)):\n",
    "    moons_df = make_moons_dataframe(n_samples=1000, noise_level=noise_level)\n",
    "    return px.scatter(moons_df, x='x', y='y', color = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3299f00-00b8-4703-8568-35de2913a487",
   "metadata": {},
   "source": [
    "## Circles Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1498d-60e1-429e-a122-f120f5ed5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "circles_df = make_circles_dataframe(n_samples=500, noise_level=0)\n",
    "circles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef522a-e381-42e1-b321-31b3d2f3b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact\n",
    "def plot_noisy_circles(noise_level = widgets.FloatSlider(value=0, min=0, max=0.5, step=0.05)):\n",
    "    df = make_circles_dataframe(1000, noise_level)\n",
    "    return px.scatter(df, x='x', y='y', color = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68124026-b4bc-4022-81ee-158175f9e732",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c6e0b-b513-4bb7-b39e-ae3baa5b3e68",
   "metadata": {},
   "source": [
    "### More hints!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad0ce4-d598-4e30-ab43-dd9a064d8dd8",
   "metadata": {},
   "source": [
    "If you'll build the datasets dataframe correctly, you'll have **one** dataframe that has dataset_name and noise_level colmuns, as well as the regular x,y,label colmns. To unsure you've appended everything correctly, groupby the proper colmuns and look at the size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d99fc-102f-4b04-8962-1e85e8909cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use proper groupby statement to ensure the datasets dataframe contains data as expected. You should see the following result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e1094-232b-46f2-ba89-856e14fab58b",
   "metadata": {},
   "source": [
    "Your "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58ae49-7d87-462b-b681-61536ae4bca8",
   "metadata": {},
   "source": [
    "You experiment code should look something like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6dca06-01af-437e-8eb1-d559cdb96741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_type = ['circles', 'moons']\n",
    "k_folds = 10\n",
    "n_samples = [10, 50, 100, 1000, 10000]\n",
    "noise_levels = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "clf_types = ['log_reg', 'svm']\n",
    "hp_range = <'Your hyper parameters ranges here'>\n",
    "regularization_values = <'Your regularization values here'>\n",
    "results = []\n",
    "for ds_type in datasets_type:\n",
    "    print(f'Working on {ds_type}')\n",
    "    for nl in noise_levels:\n",
    "        for n in n_samples:\n",
    "            ds = datasets.query(<'your query here'>).head(n)\n",
    "            print(f'Starting {k_folds}-fold cross validation for {ds_type} datasets with {n} samples and noise level {nl}. Going to train {clf_types} classifiers.')\n",
    "            for k in range(k_folds):\n",
    "                X, Y = <'Your code here'>\n",
    "                x_train,x_test,y_train,y_test= <'Your code here'>\n",
    "                for clf_type in clf_types:\n",
    "                    if clf_type == 'log_reg':\n",
    "                        for regularization_value in regularization_values:\n",
    "                            train_acc, test_acc = <'Your code here'>\n",
    "                            results.append(<'Your code here'>)\n",
    "                    if clf_type == 'svm':\n",
    "                        for gamma in hp_range:\n",
    "                            train_acc, test_acc = <'Your code here'>\n",
    "                            results.append(<'Your code here'>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62596e-1d3e-4a20-afb9-4880ed4fcd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbd8ab-dc9a-4c23-aa0a-a5b555acd70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c22ca672-ed7b-4025-8434-6096b0ba4e50",
   "metadata": {},
   "source": [
    "## Create data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce03eb6-482c-4f18-b4d3-215a64c9e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0844a16e-4718-4ca7-9a2a-c7ab150472e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 7)\n",
      "Index(['x', 'y', 'label', 'datasets_type', 'noise_levels', 'x2', 'y2'], dtype='object')\n",
      "             x         y label datasets_type  noise_levels        x2        y2\n",
      "2568  1.048790 -0.492513     1         moons           0.3  1.099960  0.242569\n",
      "9617  0.797077  0.711785     0         moons           0.2  0.635332  0.506637\n",
      "2063  0.304127 -0.743441     0       circles           0.3  0.092493  0.552704\n",
      "6166 -0.676227 -0.176884     0       circles           0.4  0.457283  0.031288\n",
      "6699  0.101293 -0.351772     1         moons           0.2  0.010260  0.123743\n",
      "9795 -1.099359  0.478906     0         moons           0.2  1.208591  0.229351\n",
      "7401 -0.063479 -0.866252     0       circles           0.1  0.004030  0.750392\n",
      "2698  0.919893 -0.278112     0       circles           0.3  0.846203  0.077346\n",
      "2332 -0.667669  0.743002     0         moons           0.1  0.445782  0.552052\n",
      "1443 -0.913174  0.287846     1       circles           0.3  0.833888  0.082855\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "#import ipywidgets as widgets\n",
    "from sklearn.datasets import make_moons,make_circles\n",
    "\n",
    "def  make_circles_dataframe(n_samples=500, noise_level=0):\n",
    "        features, true_labels =make_circles(n_samples=n_samples,noise=noise_level)\n",
    "        circles_df = pd.DataFrame([[x, y, l] for (x,y),l in zip(features, true_labels)], columns=['x','y','label'])\n",
    "        circles_df.label =circles_df.label.astype(str)\n",
    "        circles_df['datasets_type']='circles' \n",
    "        circles_df['noise_levels']=noise_level \n",
    "        return  circles_df\n",
    "    \n",
    "def  make_moons_dataframe(n_samples=500, noise_level=0):\n",
    "        features, true_labels = make_moons(n_samples=n_samples,noise=noise_level)\n",
    "        moons_df = pd.DataFrame([[x, y, l] for (x,y),l in zip(features, true_labels)], columns=['x','y','label'])\n",
    "        moons_df.label =moons_df.label.astype(str)\n",
    "        moons_df['datasets_type']='moons' \n",
    "        moons_df['noise_levels']=noise_level\n",
    "        return  moons_df   \n",
    "    \n",
    "circles_df = make_circles_dataframe(n_samples=500, noise_level=0)\n",
    "moons_df = make_moons_dataframe(n_samples=1000, noise_level=0.1)\n",
    "#circles_df\n",
    "#moons_df\n",
    "#fig = px.scatter(moons_df, x='x', y='y', color='label')\n",
    "#fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "#fig.show() \n",
    "#print(moons_df.sample(25))\n",
    "\n",
    "full_df=pd.DataFrame()\n",
    "for noise in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    circles_df = make_circles_dataframe(n_samples=10000, noise_level=noise)\n",
    "    circles_df['x2']= circles_df['x']**2\n",
    "    circles_df['y2']= circles_df['y']**2\n",
    "   \n",
    "    moons_df = make_moons_dataframe(n_samples=10000, noise_level=noise)\n",
    "    moons_df['x2']= moons_df['x']**2\n",
    "    moons_df['y2']= moons_df['y']**2\n",
    "    \n",
    "    full_df=full_df.append([circles_df, moons_df])\n",
    "   \n",
    "print(full_df.shape)\n",
    "print(full_df.columns)\n",
    "print(full_df.sample(10))\n",
    "#print(full_df.groupby('datasets_type').noise_levels.value_counts())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83d5912e-0472-433d-86f7-79180f8dfe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae0fa58c4d14a8d9c6d753d666345f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "full_df['str_label']=full_df['label'].apply(str)\n",
    "import ipywidgets as widgets\n",
    "@widgets.interact\n",
    "def plot_provider_success_rate_per_region(noise_levels=full_df.noise_levels.unique()):\n",
    "    data = full_df.loc[full_df['noise_levels']==noise_levels].reset_index()\n",
    "    fig = px.scatter(data, x='x', y='y',color='str_label', facet_row='datasets_type',height=600)#,\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52db150-8317-4071-ae5e-ba0ad3e15b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebde59db15364c0ead04a4d295504dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "full_df['str_label']=full_df['label'].apply(str)\n",
    "import ipywidgets as widgets\n",
    "@widgets.interact\n",
    "def plot_provider_success_rate_per_region(noise_levels=full_df.noise_levels.unique()):\n",
    "    data = full_df.loc[full_df['noise_levels']==noise_levels].reset_index()\n",
    "    fig = px.scatter(data, x='x2', y='y2',color='str_label', facet_row='datasets_type',height=600)#,\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e146ad2-738e-4336-b228-f18d658cbc9d",
   "metadata": {},
   "source": [
    "## Building an experiment\n",
    "### def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8cf07e2-0424-46cb-bb00-935811af0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def split_full_dataset(full_dataset,data_type,noise,n_samples):\n",
    "    ds =full_dataset.query('datasets_type==@data_type and noise_levels==@noise').head(n_samples)\n",
    "    return ds\n",
    "\n",
    "def select_folds_train_test_split(split_dataset,k_folds,k,list_columns):\n",
    "    row_in_folder=split_dataset.shape[0]/k_folds\n",
    "    ds_test=split_dataset.iloc[int(k*row_in_folder):int(k*row_in_folder+row_in_folder)]\n",
    "    ds_train=split_dataset[~split_dataset.index.isin(ds_test.index)]\n",
    "    x_test,y_test = ds_test[list_columns],  ds_test['label']#.values\n",
    "    x_train,y_train = ds_train[list_columns], ds_train['label']#.values\n",
    "    return x_train,x_test,y_train,y_test      \n",
    "                \n",
    "def log_reg_model(regularization_value,x_train,x_test,y_train,y_test):\n",
    "    log_reg = LogisticRegression(penalty='l2', C=regularization_value)\n",
    "    log_reg.fit(x_train,y_train)\n",
    "    predict_train=log_reg.predict(x_train)\n",
    "    predict_test=log_reg.predict(x_test)\n",
    "    TRE=accuracy_score(predict_train,y_train)\n",
    "    TESTE=accuracy_score(predict_test,y_test)\n",
    "    E_DIFF=TRE-TESTE\n",
    "\n",
    "    return  predict_test,TRE,TESTE, E_DIFF\n",
    "\n",
    "def knn_model(k, x_train,x_test,y_train,y_test):\n",
    "    try:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k) \n",
    "        knn.fit(x_train,y_train)\n",
    "        predict_train=knn.predict(x_train)\n",
    "        predict_test=knn.predict(x_test)  \n",
    "    except:\n",
    "        knn = KNeighborsClassifier(n_neighbors=9)                         \n",
    "        knn.fit(x_train,y_train)\n",
    "        predict_train=knn.predict(x_train)\n",
    "        predict_test=knn.predict(x_test)                     \n",
    "\n",
    "    TRE=accuracy_score(predict_train,y_train)\n",
    "    TESTE=accuracy_score(predict_test,y_test)\n",
    "    E_DIFF=TRE-TESTE\n",
    "    return  predict_test,TRE,TESTE, E_DIFF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7248ca7b-ab6b-4c78-8ee3-3f6274177653",
   "metadata": {},
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "988ecd95-fb01-4f03-879e-13578723ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on circles\n",
      "Starting 10-fold cross validation for circles datasets with 10 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 50 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 100 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 1000 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10000 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 50 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 100 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 1000 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10000 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 50 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 100 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 1000 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10000 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 50 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 100 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 1000 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10000 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 50 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 100 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 1000 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10000 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 50 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 100 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 1000 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for circles datasets with 10000 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Working on moons\n",
      "Starting 10-fold cross validation for moons datasets with 10 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 50 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 100 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 1000 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10000 samples and noise level 0. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 50 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 100 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 1000 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10000 samples and noise level 0.1. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 50 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 100 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 1000 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10000 samples and noise level 0.2. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 50 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 100 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 1000 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10000 samples and noise level 0.3. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 50 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 100 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 1000 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10000 samples and noise level 0.4. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 50 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 100 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 1000 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n",
      "Starting 10-fold cross validation for moons datasets with 10000 samples and noise level 0.5. Going to train ['log_reg', 'knn'] classifiers.\n"
     ]
    }
   ],
   "source": [
    "#data type\n",
    "datasets_type = ['circles', 'moons']\n",
    "n_samples =[10, 50, 100, 1000, 10000]\n",
    "noise_levels = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# model name\n",
    "clf_types = ['log_reg', 'knn']\n",
    "# grid pramter\n",
    "K_valuo =[1,3,5,11,21,31,41,51,53,55]\n",
    "regularization_values =[0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "k_folds = 10\n",
    "results_log_reg =[]\n",
    "results_knn = []\n",
    "\n",
    "for ds_type,columns in zip(datasets_type,[['x2','y2'],['x','y']]): # data type    \n",
    "    print(f'Working on {ds_type}')\n",
    "    \n",
    "    for nl in noise_levels: # select noise levels\n",
    "        for n in n_samples: # select numver samples\n",
    "            ds =split_full_dataset(full_df,ds_type,nl,n)\n",
    "            print(f'Starting {k_folds}-fold cross validation for {ds_type} datasets with {n} samples and noise level {nl}. Going to train {clf_types} classifiers.')\n",
    "            row_in_folder=n/k_folds\n",
    "            for kf in range(k_folds): # K-Fold Cross-Validation and split to training set  validation set\n",
    "                x_train,x_test,y_train,y_test=select_folds_train_test_split(ds,k_folds,kf,columns)\n",
    "                for clf_type in clf_types:\n",
    "                 \n",
    "                    if clf_type == 'log_reg':\n",
    "                        for regularization_value in regularization_values:\n",
    "                            #print('regularization_value',regularization_value)\n",
    "                            predict_test,train_acc, test_acc,diff_acc =log_reg_model(regularization_value,x_train,x_test,y_train,y_test)\n",
    "                            #print( clf_type,  train_acc, test_acc,diff_acc)\n",
    "                            results_log_reg.append((clf_type,ds_type,nl,n,kf,regularization_value, train_acc, test_acc,diff_acc ))\n",
    "  \n",
    "                                      \n",
    "                    if clf_type == 'knn':\n",
    "                        for k in K_valuo:\n",
    "                            #print('k',k)\n",
    "                            try:\n",
    "                                predict_test ,train_acc, test_acc,diff_acc =knn_model(k, x_train,x_test,y_train,y_test)\n",
    "                            except:\n",
    "                                 predict_test,train_acc, test_acc,diff_acc =knn_model(9, x_train,x_test,y_train,y_test)\n",
    "                            \n",
    "                                      \n",
    "                            results_knn.append((clf_type,ds_type,nl,n,kf,k, train_acc, test_acc,diff_acc ))\n",
    "                      \n",
    "\n",
    "                                                       \n",
    "                           \n",
    "log_reg_df=pd.DataFrame(results_log_reg ,columns=['model', 'ds_type','noise_levels','n_samples' ,'k_folds', 'regularization_value','TRE','TESTE', 'E_DIFF'])   \n",
    "knn_df=pd.DataFrame(results_knn,columns=['model', 'ds_type','noise_levels','n_samples', 'k_folds', 'k','TRE','TESTE', 'E_DIFF']) \n",
    "\n",
    "\n",
    "\n",
    "#log_reg_df.to_csv('log_reg_df_nwe.csv')\n",
    "#knn_df.to_csv('knn_df_nwe.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4964f38-b455-4f25-aa1d-16f5419817d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>noise_levels</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>k_folds</th>\n",
       "      <th>k</th>\n",
       "      <th>TRE</th>\n",
       "      <th>TESTE</th>\n",
       "      <th>E_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>circles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>circles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>circles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>circles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>circles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>knn</td>\n",
       "      <td>moons</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>0.832333</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.009333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>knn</td>\n",
       "      <td>moons</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.006556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>knn</td>\n",
       "      <td>moons</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>0.830889</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.004889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>knn</td>\n",
       "      <td>moons</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>0.830444</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.003444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>knn</td>\n",
       "      <td>moons</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>0.830444</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  ds_type  noise_levels  n_samples  k_folds   k       TRE  TESTE  \\\n",
       "0      knn  circles           0.0         10        0   1  1.000000  1.000   \n",
       "1      knn  circles           0.0         10        0   3  0.888889  1.000   \n",
       "2      knn  circles           0.0         10        0   5  0.666667  1.000   \n",
       "3      knn  circles           0.0         10        0  11  0.666667  1.000   \n",
       "4      knn  circles           0.0         10        0  21  0.666667  1.000   \n",
       "...    ...      ...           ...        ...      ...  ..       ...    ...   \n",
       "5995   knn    moons           0.5      10000        9  31  0.832333  0.823   \n",
       "5996   knn    moons           0.5      10000        9  41  0.830556  0.824   \n",
       "5997   knn    moons           0.5      10000        9  51  0.830889  0.826   \n",
       "5998   knn    moons           0.5      10000        9  53  0.830444  0.827   \n",
       "5999   knn    moons           0.5      10000        9  55  0.830444  0.828   \n",
       "\n",
       "        E_DIFF  \n",
       "0     0.000000  \n",
       "1    -0.111111  \n",
       "2    -0.333333  \n",
       "3    -0.333333  \n",
       "4    -0.333333  \n",
       "...        ...  \n",
       "5995  0.009333  \n",
       "5996  0.006556  \n",
       "5997  0.004889  \n",
       "5998  0.003444  \n",
       "5999  0.002444  \n",
       "\n",
       "[6000 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_df\n",
    "knn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e9f0e-4fbe-4ed2-9f19-fc3d34da97ac",
   "metadata": {},
   "source": [
    "## Analysing the expermient results\n",
    "1. For SVM only, For dataset of size 10k and for each dataset, What are the best model params? How stable is it?\n",
    "1. For SVM only, For dataset of size 10k and for each dataset, What is the most stable model and model params? How good is it in comparison to other models? Explain using bias and variance terminoligy.\n",
    "1. Does regularization help for linear models? consider different datasets sizes.\n",
    "1. For a given noise level of your chioce, How does the train, test and difference error changes with increasing data sizes? (answer for svm and LR seperatly)\n",
    "1. For a given noise level of your chioce, How does the train, test and difference error changes with increasing model complexity? (answer for svm and LR seperatly)\n",
    "1. Are the noise level effect the number of datapoints needed to reach optimal test results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5e948-496d-46f6-9c20-69771f88df73",
   "metadata": {},
   "source": [
    "#  get model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d2b959-65d1-4f79-961c-acef4968ee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0    model  ds_type  noise_levels  n_samples  k_folds  \\\n",
      "3776        3776  log_reg    moons           0.4       1000        9   \n",
      "1033        1033  log_reg  circles           0.2      10000        7   \n",
      "4019        4019  log_reg    moons           0.5        100        4   \n",
      "636          636  log_reg  circles           0.1      10000        0   \n",
      "1014        1014  log_reg  circles           0.2      10000        4   \n",
      "3068        3068  log_reg    moons           0.2       1000        8   \n",
      "433          433  log_reg  circles           0.1         50        1   \n",
      "2324        2324  log_reg    moons           0.0       1000        2   \n",
      "1152        1152  log_reg  circles           0.3         50        4   \n",
      "2756        2756  log_reg    moons           0.1      10000        3   \n",
      "\n",
      "      regularization_value       TRE  TESTE    E_DIFF  \n",
      "3776                 1.000  0.831111  0.820  0.011111  \n",
      "1033                10.000  0.508111  0.474  0.034111  \n",
      "4019                 0.010  0.633333  0.600  0.033333  \n",
      "636               1000.000  0.500111  0.480  0.020111  \n",
      "1014              1000.000  0.514333  0.512  0.002333  \n",
      "3068                 0.100  0.845556  0.890 -0.044444  \n",
      "433               1000.000  0.622222  0.200  0.422222  \n",
      "2324                 0.001  0.788889  0.790 -0.001111  \n",
      "1152                10.000  0.622222  0.400  0.222222  \n",
      "2756               100.000  0.881778  0.895 -0.013222  \n",
      "Index(['Unnamed: 0', 'model', 'ds_type', 'noise_levels', 'n_samples',\n",
      "       'k_folds', 'regularization_value', 'TRE', 'TESTE', 'E_DIFF'],\n",
      "      dtype='object')\n",
      "['log_reg']\n",
      "['circles' 'moons']\n",
      "[0.  0.1 0.2 0.3 0.4 0.5]\n",
      "[   10    50   100  1000 10000]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "import ipywidgets as widgets\n",
    "\n",
    "log_reg_df=pd.read_csv('log_reg_df.csv')\n",
    "knn_df=pd.read_csv('knn_df.csv')\n",
    "\n",
    "data_model=log_reg_df\n",
    "print(data_model.sample(10))\n",
    "print(data_model.columns)\n",
    "c=data_model.columns\n",
    "print(data_model[c[1]].unique())\n",
    "print(data_model[c[2]].unique())\n",
    "print(data_model[c[3]].unique())\n",
    "print(data_model[c[4]].unique())\n",
    "print(data_model[c[5]].unique())\n",
    "print(data_model[c[6]].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90af18-a966-44d7-b174-7d3c7e31586d",
   "metadata": {},
   "source": [
    "### plot model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629720a-026d-4606-a1f6-d342e955f58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7afd9d8b-d4cc-4a2b-8098-62fc9cb68c95",
   "metadata": {},
   "source": [
    "### 1 - For SVM only, For dataset of size 10k and for each dataset\n",
    "### What are the best model params? How stable is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34be300e-5391-4bf7-9542-1c480e338c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ds_type  noise_levels  pramter   TESTE\n",
      "0    circles           0.0        1  1.0000\n",
      "1    circles           0.0        3  1.0000\n",
      "2    circles           0.0        5  1.0000\n",
      "3    circles           0.0       11  1.0000\n",
      "4    circles           0.0       21  1.0000\n",
      "..       ...           ...      ...     ...\n",
      "115    moons           0.5       31  0.8190\n",
      "116    moons           0.5       41  0.8224\n",
      "117    moons           0.5       51  0.8233\n",
      "118    moons           0.5       53  0.8239\n",
      "119    moons           0.5       55  0.8239\n",
      "\n",
      "[120 rows x 4 columns]\n",
      "    ds_type  noise_levels   valuo  pramter    stable\n",
      "0   circles           0.0  1.0000      1.0  0.000000\n",
      "1   circles           0.1  0.8391     53.0  0.021031\n",
      "2   circles           0.2  0.6825     53.0  0.028181\n",
      "3   circles           0.3  0.6162     55.0  0.021752\n",
      "4   circles           0.4  0.5812     53.0  0.019109\n",
      "5   circles           0.5  0.5615     55.0  0.018865\n",
      "6     moons           0.0  1.0000      1.0  0.000000\n",
      "7     moons           0.1  0.9990      3.0  0.000140\n",
      "8     moons           0.2  0.9689     41.0  0.005191\n",
      "9     moons           0.3  0.9110     53.0  0.010778\n",
      "10    moons           0.4  0.8652     53.0  0.022720\n",
      "11    moons           0.5  0.8239     53.0  0.023420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a343366d596400fa668ccebe2fd22a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col', options=('pramter', 'valuo', 'stable'), value='pramter'), Ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def best_model_params(df):\n",
    "    # find bast modsel pramter by max teste \n",
    "    # and stabble by std of teste in the difference folds\n",
    "    best_TESTE=df.query('TESTE==TESTE.max()')[['TESTE']].iloc[0].values[0]\n",
    "    best_pramter=df.query('TESTE==TESTE.max()')[['pramter']].iloc[0].values[0]\n",
    "    stable=df['TESTE'].std()\n",
    "    return  pd.Series({'valuo':best_TESTE,'pramter':best_pramter,'stable':stable})\n",
    "\n",
    "# data\n",
    "data=knn_df.query('n_samples==10000')\n",
    "data=data.rename(columns={'k': 'pramter'})\n",
    "#data2=data.query('ds_type ==\"moons\" and noise_levels==0.1')\n",
    "#print(data.sample(10))\n",
    "\n",
    "\n",
    "# mean k folder \n",
    "type_data_grop=data.groupby(by=['ds_type','noise_levels','pramter'])['TESTE'].mean()\n",
    "type_data_grop=type_data_grop.reset_index()\n",
    "print(type_data_grop)\n",
    "\n",
    "# best_model_params\n",
    "type_data_grop2=type_data_grop.groupby(by=['ds_type','noise_levels']).apply(lambda df:  best_model_params(df))\n",
    "type_data_grop2=type_data_grop2.reset_index()\n",
    "print(type_data_grop2)\n",
    "\n",
    "@widgets.interact\n",
    "def plot_bar_best_model_params(col=['pramter','valuo','stable']):\n",
    "    data = type_data_grop2[[col,'noise_levels','ds_type']]\n",
    "    data=data.rename(columns={col: \"y\"})\n",
    "    fig=px.bar(data, x='noise_levels', y='y', facet_row='ds_type', height=800)\n",
    "    return  fig\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "# the  bast modsel pramter depends on the noise level small for low noise level and large for high noise level\n",
    "\n",
    "# the stabble is function of noize levels and is goes down When  the noise level goes up in mood data set\n",
    "\n",
    "# the model results are better in moons  data det  and decreases with increase in noise level\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a0dce-6a3e-4f97-832c-72b40d825e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ed299c1-fd4d-4e6b-a141-208f37a0dcd2",
   "metadata": {},
   "source": [
    "### 2 - For SVM only, For dataset of size 10k and for each dataset,\n",
    "### What is the most stable model and model params? \n",
    "### How good is it in comparison to other models? Explain using bias and variance terminoligy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e67b44-02c7-45d1-8ad7-b228f3a91502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ds_type  noise_levels  pramter     valuo    stable\n",
      "0    circles           0.0        1  1.000000  0.000000\n",
      "1    circles           0.0        3  1.000000  0.000000\n",
      "2    circles           0.0        5  1.000000  0.000000\n",
      "3    circles           0.0       11  1.000000  0.000000\n",
      "4    circles           0.0       21  1.000000  0.000000\n",
      "..       ...           ...      ...       ...       ...\n",
      "115    moons           0.5       31  0.826789  0.015406\n",
      "116    moons           0.5       41  0.827133  0.014766\n",
      "117    moons           0.5       51  0.827556  0.014174\n",
      "118    moons           0.5       53  0.827300  0.014888\n",
      "119    moons           0.5       55  0.827289  0.014495\n",
      "\n",
      "[120 rows x 5 columns]\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "    ds_type  noise_levels    stable  pramter     valuo\n",
      "0   circles           0.0  0.000000      1.0  1.000000\n",
      "1   circles           0.1  0.007630     21.0  0.847344\n",
      "2   circles           0.2  0.016322      5.0  0.758267\n",
      "3   circles           0.3  0.004984     53.0  0.639556\n",
      "4   circles           0.4  0.012791     11.0  0.657289\n",
      "5   circles           0.5  0.007516     11.0  0.640522\n",
      "6     moons           0.0  0.000000      1.0  1.000000\n",
      "7     moons           0.1  0.001155      3.0  0.999200\n",
      "8     moons           0.2  0.003765      3.0  0.975667\n",
      "9     moons           0.3  0.006832      5.0  0.926456\n",
      "10    moons           0.4  0.008439     21.0  0.868144\n",
      "11    moons           0.5  0.009153      1.0  1.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b64640a9e04d37867e4fb4a30e9440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def most_stable_model(df):\n",
    "    # find bast modsel pramter by max teste \n",
    "    mean_TRE=df['TRE'].mean()\n",
    "    stable=df['TESTE'].std()\n",
    "    return  pd.Series({'valuo':mean_TRE,'stable':stable})\n",
    "\n",
    "\n",
    "def most_stable_model_2(df):\n",
    "    # find  stable model\n",
    "    stable=df.query('stable== stable.min()')[['stable']].iloc[0].values[0]\n",
    "    valuo=df.query('stable== stable.min()')[['valuo']].iloc[0].values[0]\n",
    "    pramter=df.query('stable== stable.min()')[['pramter']].iloc[0].values[0]\n",
    "    return  pd.Series({'stable':stable,'pramter': pramter,'valuo': valuo})\n",
    "\n",
    "# data\n",
    "data=knn_df.query('n_samples==10000')\n",
    "data=data.rename(columns={'k': 'pramter'})\n",
    "\n",
    "# mean k folder \n",
    "type_data_grop=data.groupby(by=['ds_type','noise_levels','pramter']).apply(lambda df:  most_stable_model(df))\n",
    "type_data_grop=type_data_grop.reset_index()\n",
    "print(type_data_grop)\n",
    "print('aaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n",
    "\n",
    "\n",
    "type_data_grop_2=type_data_grop.groupby(by=['ds_type','noise_levels']).apply(lambda df:  most_stable_model_2(df))\n",
    "type_data_grop_2=type_data_grop_2.reset_index()\n",
    "print(type_data_grop_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "type_data_grop['str_pramter']=type_data_grop['pramter'].apply(str)\n",
    "@widgets.interact\n",
    "def plot_provider_success_rate_per_region(noise_levels=type_data_grop.noise_levels.unique()):\n",
    "    data =type_data_grop.loc[type_data_grop['noise_levels']==noise_levels].reset_index()\n",
    "    fig = px.scatter(data, x='stable', y='valuo',color='str_pramter', facet_row='ds_type',height=600)#,\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48be4a3-97d1-4dcf-9163-d6202d574c21",
   "metadata": {},
   "source": [
    "### 3- Does regularization help for linear models? consider different datasets sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e7650e-7350-4006-9274-36c90bf4b1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'model', 'ds_type', 'noise_levels', 'n_samples',\n",
      "       'k_folds', 'pramter', 'TRE', 'TESTE', 'E_DIFF'],\n",
      "      dtype='object')\n",
      "     ds_type  noise_levels  n_samples   pramter   TESTE\n",
      "0    circles           0.0         10     0.001  0.0000\n",
      "1    circles           0.0         10     0.010  0.0000\n",
      "2    circles           0.0         10     0.100  0.0000\n",
      "3    circles           0.0         10     1.000  0.6000\n",
      "4    circles           0.0         10    10.000  0.6000\n",
      "..       ...           ...        ...       ...     ...\n",
      "415    moons           0.5      10000     0.100  0.8064\n",
      "416    moons           0.5      10000     1.000  0.8066\n",
      "417    moons           0.5      10000    10.000  0.8068\n",
      "418    moons           0.5      10000   100.000  0.8068\n",
      "419    moons           0.5      10000  1000.000  0.8068\n",
      "\n",
      "[420 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0489510fe84f0dbba3f937cd20031e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=log_reg_df\n",
    "data=data.rename(columns={'regularization_value': 'pramter'})\n",
    "\n",
    "print(data.columns)\n",
    "type_data_grop=data.groupby(by=['ds_type','noise_levels','n_samples','pramter'])['TESTE'].mean()\n",
    "                       \n",
    "type_data_grop=type_data_grop.reset_index()\n",
    "print(type_data_grop)\n",
    "\n",
    "type_data_grop['str_n_samples']=type_data_grop['n_samples'].apply(str)\n",
    "type_data_grop['log_pramter']=type_data_grop['pramter'].apply(np.log)\n",
    "#fig = px.scatter(type_data_grop, x='log_pramter', y='TESTE',color='str_n_samples', height=600)\n",
    "#fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "#fig.show()\n",
    "\n",
    "\n",
    "\n",
    "@widgets.interact\n",
    "def plot_provider_success_rate_per_region(noise_levels=type_data_grop.noise_levels.unique()):\n",
    "    data = type_data_grop.loc[type_data_grop['noise_levels']==noise_levels].reset_index()\n",
    "    fig = px.scatter(data, x='log_pramter', y='TESTE',color='str_n_samples', facet_row='ds_type',height=600)#,\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig\n",
    "\n",
    "\n",
    "#################################\n",
    "# regularization help for  small data set and does not affect large data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e90e2-140a-4ab7-90fa-7697da11fefe",
   "metadata": {},
   "source": [
    "### 4 For a given noise level of your chioce, \n",
    "### How does the train, test and difference error changes with increasing data sizes? (answer for svm and LR seperatly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a70db88-e908-4fbc-b91a-27d2e1209e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ds_type  noise_levels  n_samples    E_DIFF\n",
      "0   circles           0.0         10  0.445556\n",
      "1   circles           0.0         50  0.070889\n",
      "2   circles           0.0        100  0.056111\n",
      "3   circles           0.0       1000  0.002756\n",
      "4   circles           0.0      10000  0.000000\n",
      "5   circles           0.1         10  0.062222\n",
      "6   circles           0.1         50  0.124222\n",
      "7   circles           0.1        100  0.150111\n",
      "8   circles           0.1       1000  0.050644\n",
      "9   circles           0.1      10000  0.041084\n",
      "10  circles           0.2         10  0.113333\n",
      "11  circles           0.2         50  0.163778\n",
      "12  circles           0.2        100  0.116333\n",
      "13  circles           0.2       1000  0.085289\n",
      "14  circles           0.2      10000  0.085071\n",
      "15  circles           0.3         10  0.070000\n",
      "16  circles           0.3         50  0.195111\n",
      "17  circles           0.3        100  0.161333\n",
      "18  circles           0.3       1000  0.111811\n",
      "19  circles           0.3      10000  0.108446\n",
      "20  circles           0.4         10  0.537778\n",
      "21  circles           0.4         50  0.109778\n",
      "22  circles           0.4        100  0.104000\n",
      "23  circles           0.4       1000  0.111678\n",
      "24  circles           0.4      10000  0.117889\n",
      "25  circles           0.5         10  0.060000\n",
      "26  circles           0.5         50  0.138667\n",
      "27  circles           0.5        100  0.113222\n",
      "28  circles           0.5       1000  0.125011\n",
      "29  circles           0.5      10000  0.125907\n",
      "30    moons           0.0         10  0.416667\n",
      "31    moons           0.0         50  0.016889\n",
      "32    moons           0.0        100  0.004444\n",
      "33    moons           0.0       1000  0.000000\n",
      "34    moons           0.0      10000  0.000000\n",
      "35    moons           0.1         10  0.007778\n",
      "36    moons           0.1         50  0.020667\n",
      "37    moons           0.1        100  0.008667\n",
      "38    moons           0.1       1000  0.000411\n",
      "39    moons           0.1      10000  0.000270\n",
      "40    moons           0.2         10  0.038889\n",
      "41    moons           0.2         50  0.030667\n",
      "42    moons           0.2        100  0.011000\n",
      "43    moons           0.2       1000  0.007578\n",
      "44    moons           0.2      10000  0.007871\n",
      "45    moons           0.3         10  0.053333\n",
      "46    moons           0.3         50  0.046222\n",
      "47    moons           0.3        100  0.022778\n",
      "48    moons           0.3       1000  0.025022\n",
      "49    moons           0.3      10000  0.022683\n",
      "50    moons           0.4         10  0.035556\n",
      "51    moons           0.4         50  0.072000\n",
      "52    moons           0.4        100  0.072111\n",
      "53    moons           0.4       1000  0.036389\n",
      "54    moons           0.4      10000  0.035156\n",
      "55    moons           0.5         10  0.475556\n",
      "56    moons           0.5         50  0.075111\n",
      "57    moons           0.5        100  0.047667\n",
      "58    moons           0.5       1000  0.048900\n",
      "59    moons           0.5      10000  0.045212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7526e84aac64bb7a968e2fb22f781ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ds_type  noise_levels  n_samples    E_DIFF\n",
      "0   circles           0.0         10  0.317460\n",
      "1   circles           0.0         50  0.031429\n",
      "2   circles           0.0        100  0.022857\n",
      "3   circles           0.0       1000  0.044587\n",
      "4   circles           0.0      10000  0.028690\n",
      "5   circles           0.1         10  0.120635\n",
      "6   circles           0.1         50  0.041587\n",
      "7   circles           0.1        100  0.034444\n",
      "8   circles           0.1       1000  0.017397\n",
      "9   circles           0.1      10000  0.021763\n",
      "10  circles           0.2         10  0.180952\n",
      "11  circles           0.2         50  0.080952\n",
      "12  circles           0.2        100  0.116984\n",
      "13  circles           0.2       1000  0.037492\n",
      "14  circles           0.2      10000  0.028460\n",
      "15  circles           0.3         10  0.058730\n",
      "16  circles           0.3         50  0.147619\n",
      "17  circles           0.3        100  0.082698\n",
      "18  circles           0.3       1000  0.041079\n",
      "19  circles           0.3      10000  0.009321\n",
      "20  circles           0.4         10  0.458730\n",
      "21  circles           0.4         50  0.025397\n",
      "22  circles           0.4        100  0.019048\n",
      "23  circles           0.4       1000  0.024683\n",
      "24  circles           0.4      10000  0.008656\n",
      "25  circles           0.5         10  0.090476\n",
      "26  circles           0.5         50  0.115238\n",
      "27  circles           0.5        100  0.027937\n",
      "28  circles           0.5       1000  0.026905\n",
      "29  circles           0.5      10000  0.023514\n",
      "30    moons           0.0         10  0.319048\n",
      "31    moons           0.0         50  0.039683\n",
      "32    moons           0.0        100  0.020317\n",
      "33    moons           0.0       1000  0.000190\n",
      "34    moons           0.0      10000  0.000144\n",
      "35    moons           0.1         10  0.080952\n",
      "36    moons           0.1         50  0.027937\n",
      "37    moons           0.1        100  0.009048\n",
      "38    moons           0.1       1000  0.001968\n",
      "39    moons           0.1      10000  0.000040\n",
      "40    moons           0.2         10  0.057143\n",
      "41    moons           0.2         50  0.048254\n",
      "42    moons           0.2        100  0.009365\n",
      "43    moons           0.2       1000  0.001571\n",
      "44    moons           0.2      10000  0.000163\n",
      "45    moons           0.3         10  0.068254\n",
      "46    moons           0.3         50  0.046984\n",
      "47    moons           0.3        100  0.018413\n",
      "48    moons           0.3       1000 -0.000175\n",
      "49    moons           0.3      10000  0.000321\n",
      "50    moons           0.4         10  0.157143\n",
      "51    moons           0.4         50  0.032063\n",
      "52    moons           0.4        100  0.031746\n",
      "53    moons           0.4       1000  0.002413\n",
      "54    moons           0.4      10000 -0.000068\n",
      "55    moons           0.5         10  0.315873\n",
      "56    moons           0.5         50  0.013333\n",
      "57    moons           0.5        100  0.011587\n",
      "58    moons           0.5       1000  0.000683\n",
      "59    moons           0.5      10000 -0.000132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82a93a06fc040c4be64c7cdcddf309d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#knn\n",
    "data=knn_df#.query('noise_levels==0.5')\n",
    "\n",
    "\n",
    "type_data_grop_knn=data.groupby(by=['ds_type','noise_levels','n_samples'])['E_DIFF'].mean()\n",
    "type_data_grop_knn=type_data_grop_knn.reset_index()\n",
    "print(type_data_grop_knn)   \n",
    "\n",
    "type_data_grop_knn['log_n_samples']=type_data_grop_knn['n_samples'].apply(np.log)\n",
    "#type_data_grop_knn['str_k']=type_data_grop_knn['k'].apply(str)\n",
    "@widgets.interact\n",
    "def plot_provider_success_rate_per_region(noise_levels=type_data_grop_knn.noise_levels.unique()):\n",
    "    data =type_data_grop_knn.loc[type_data_grop_knn['noise_levels']==noise_levels].reset_index()\n",
    "    fig = px.scatter(data, x='log_n_samples', y='E_DIFF', facet_row='ds_type',height=600)\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#log_reg\n",
    "data=log_reg_df#.query('noise_levels==0.5')\n",
    "\n",
    "type_data_groplog_reg=data.groupby(by=['ds_type','noise_levels','n_samples'])['E_DIFF'].mean()\n",
    "type_data_groplog_reg=type_data_groplog_reg.reset_index()\n",
    "print(type_data_groplog_reg)   \n",
    "\n",
    "type_data_groplog_reg['log_n_samples']=type_data_groplog_reg['n_samples'].apply(np.log)\n",
    "@widgets.interact\n",
    "\n",
    "def plot_provider_success_rate_per_region(noise_levels=type_data_grop.noise_levels.unique()):\n",
    "    data =type_data_groplog_reg.loc[type_data_groplog_reg['noise_levels']==noise_levels].reset_index()\n",
    "    fig = px.scatter(data, x='log_n_samples', y='E_DIFF',facet_row='ds_type',height=600)\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################3\n",
    "# The error difference decreases with an increase in the number of samples\n",
    "\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e0990-b73c-4ec3-97f7-4ffa2e5c5605",
   "metadata": {},
   "source": [
    "#### 5  For a given noise level of your chioce, How does the train, test and difference error changes\n",
    "#### with increasing model complexity? (answer for svm and LR seperatly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "014c1d7a-ad7b-4f7e-a346-ffe0e7c0ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ds_type  noise_levels  n_samples   pramter   TESTE str_n_samples  \\\n",
      "0    circles           0.0         10     0.001  0.0000            10   \n",
      "1    circles           0.0         10     0.010  0.0000            10   \n",
      "2    circles           0.0         10     0.100  0.0000            10   \n",
      "3    circles           0.0         10     1.000  0.6000            10   \n",
      "4    circles           0.0         10    10.000  0.6000            10   \n",
      "..       ...           ...        ...       ...     ...           ...   \n",
      "415    moons           0.5      10000     0.100  0.8064         10000   \n",
      "416    moons           0.5      10000     1.000  0.8066         10000   \n",
      "417    moons           0.5      10000    10.000  0.8068         10000   \n",
      "418    moons           0.5      10000   100.000  0.8068         10000   \n",
      "419    moons           0.5      10000  1000.000  0.8068         10000   \n",
      "\n",
      "     log_pramter  \n",
      "0      -6.907755  \n",
      "1      -4.605170  \n",
      "2      -2.302585  \n",
      "3       0.000000  \n",
      "4       2.302585  \n",
      "..           ...  \n",
      "415    -2.302585  \n",
      "416     0.000000  \n",
      "417     2.302585  \n",
      "418     4.605170  \n",
      "419     6.907755  \n",
      "\n",
      "[420 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51a1f895d714354aa1a04161e6b6135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ds_type', 'noise_levels', 'n_samples', 'regularization_value',\n",
      "       'E_DIFF'],\n",
      "      dtype='object')\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaa\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad2a952e8df4de282df00181337a294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise_levels', options=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0.0),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#knn \n",
    "\n",
    "data=knn_df#.query('noise_levels==0.5')\n",
    "\n",
    "\n",
    "type_data_grop_knn=data.groupby(by=['ds_type','noise_levels','n_samples','k'])['E_DIFF'].mean()\n",
    "type_data_grop_knn=type_data_grop_knn.reset_index()\n",
    "print(type_data_grop)   \n",
    "\n",
    "type_data_grop_knn['log_n_samples']=type_data_grop_knn['n_samples'].apply(np.log)\n",
    "type_data_grop_knn['str_n_samples']=type_data_grop_knn['n_samples'].apply(str)\n",
    "type_data_grop_knn['str_k']=type_data_grop_knn['k'].apply(str)\n",
    "\n",
    "@widgets.interact\n",
    "def plot_provider_success_rate_per_region(noise_levels=type_data_grop_knn.noise_levels.unique()):\n",
    "    data =type_data_grop_knn.loc[type_data_grop_knn['noise_levels']==noise_levels].reset_index().reset_index()\n",
    "    fig = px.scatter(data, x='str_k', y='E_DIFF',color='str_n_samples', facet_row='ds_type',height=600)\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#log_reg \n",
    "data=log_reg_df#.query('noise_levels==0.5')\n",
    "type_data_grop_log_reg=data.groupby(by=['ds_type','noise_levels','n_samples','regularization_value'])['E_DIFF'].mean()\n",
    "type_data_grop_log_reg=type_data_grop_log_reg.reset_index()\n",
    "print(type_data_grop_log_reg.columns)\n",
    "   \n",
    "\n",
    "type_data_grop_log_reg['log_n_samples']=type_data_grop_log_reg['n_samples'].apply(np.log)\n",
    "type_data_grop_log_reg['str_n_samples']=type_data_grop_log_reg['n_samples'].apply(str)\n",
    "type_data_grop_log_reg['str_regularization_value']=type_data_grop_log_reg['regularization_value'].apply(str)\n",
    "@widgets.interact\n",
    "\n",
    "def plot_provider_success_rate_per_region(noise_levels=data.noise_levels.unique()):\n",
    "    data =type_data_grop_log_reg.loc[type_data_grop_log_reg['noise_levels']==noise_levels].reset_index()\n",
    "    fig = px.scatter(data, x='str_regularization_value', y='E_DIFF',color='str_n_samples',facet_row='ds_type',height=600)\n",
    "    fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    return  fig\n",
    "\n",
    "#########################################################3\n",
    "\n",
    "\n",
    "\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b57eb-323e-4da2-b04e-b7de9b09470e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6 Are the noise level effect the number \n",
    "#### of datapoints needed to reach optimal test results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f983664a-96f0-43a0-98a4-0290e1cc3697",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'model', 'ds_type', 'noise_levels', 'n_samples',\n",
      "       'k_folds', 'regularization_value', 'TRE', 'TESTE', 'E_DIFF'],\n",
      "      dtype='object')\n",
      "    ds_type  noise_levels  n_samples     valuo\n",
      "0   circles           0.0         10  0.342857\n",
      "1   circles           0.0         50  0.614286\n",
      "2   circles           0.0        100  0.564286\n",
      "3   circles           0.0       1000  0.460429\n",
      "4   circles           0.0      10000  0.468571\n",
      "5   circles           0.1         10  0.600000\n",
      "6   circles           0.1         50  0.525714\n",
      "7   circles           0.1        100  0.521429\n",
      "8   circles           0.1       1000  0.506429\n",
      "9   circles           0.1      10000  0.484229\n",
      "10  circles           0.2         10  0.442857\n",
      "11  circles           0.2         50  0.457143\n",
      "12  circles           0.2        100  0.420000\n",
      "13  circles           0.2       1000  0.471000\n",
      "14  circles           0.2      10000  0.479443\n",
      "15  circles           0.3         10  0.657143\n",
      "16  circles           0.3         50  0.414286\n",
      "17  circles           0.3        100  0.495714\n",
      "18  circles           0.3       1000  0.481429\n",
      "19  circles           0.3      10000  0.495014\n",
      "20  circles           0.4         10  0.128571\n",
      "21  circles           0.4         50  0.614286\n",
      "22  circles           0.4        100  0.577143\n",
      "23  circles           0.4       1000  0.498857\n",
      "24  circles           0.4      10000  0.496257\n",
      "25  circles           0.5         10  0.614286\n",
      "26  circles           0.5         50  0.485714\n",
      "27  circles           0.5        100  0.561429\n",
      "28  circles           0.5       1000  0.479857\n",
      "29  circles           0.5      10000  0.480386\n",
      "30    moons           0.0         10  0.500000\n",
      "31    moons           0.0         50  0.800000\n",
      "32    moons           0.0        100  0.804286\n",
      "33    moons           0.0       1000  0.868714\n",
      "34    moons           0.0      10000  0.879829\n",
      "35    moons           0.1         10  0.771429\n",
      "36    moons           0.1         50  0.800000\n",
      "37    moons           0.1        100  0.824286\n",
      "38    moons           0.1       1000  0.875714\n",
      "39    moons           0.1      10000  0.872800\n",
      "40    moons           0.2         10  0.814286\n",
      "41    moons           0.2         50  0.785714\n",
      "42    moons           0.2        100  0.800000\n",
      "43    moons           0.2       1000  0.839429\n",
      "44    moons           0.2      10000  0.860014\n",
      "45    moons           0.3         10  0.685714\n",
      "46    moons           0.3         50  0.742857\n",
      "47    moons           0.3        100  0.798571\n",
      "48    moons           0.3       1000  0.822000\n",
      "49    moons           0.3      10000  0.845143\n",
      "50    moons           0.4         10  0.700000\n",
      "51    moons           0.4         50  0.708571\n",
      "52    moons           0.4        100  0.700000\n",
      "53    moons           0.4       1000  0.817143\n",
      "54    moons           0.4      10000  0.830143\n",
      "55    moons           0.5         10  0.371429\n",
      "56    moons           0.5         50  0.742857\n",
      "57    moons           0.5        100  0.761429\n",
      "58    moons           0.5       1000  0.799143\n",
      "59    moons           0.5      10000  0.804557\n",
      "    ds_type  noise_levels  optimalresults  number_datapoints\n",
      "0   circles           0.0        0.614286               50.0\n",
      "1   circles           0.1        0.600000               10.0\n",
      "2   circles           0.2        0.479443            10000.0\n",
      "3   circles           0.3        0.657143               10.0\n",
      "4   circles           0.4        0.614286               50.0\n",
      "5   circles           0.5        0.614286               10.0\n",
      "6     moons           0.0        0.879829            10000.0\n",
      "7     moons           0.1        0.875714             1000.0\n",
      "8     moons           0.2        0.860014            10000.0\n",
      "9     moons           0.3        0.845143            10000.0\n",
      "10    moons           0.4        0.830143            10000.0\n",
      "11    moons           0.5        0.804557            10000.0\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "Index(['model', 'ds_type', 'noise_levels', 'n_samples', 'k_folds', 'k', 'TRE',\n",
      "       'TESTE', 'E_DIFF'],\n",
      "      dtype='object')\n",
      "    ds_type  noise_levels  n_samples    valuo\n",
      "0   circles           0.0         10  0.20000\n",
      "1   circles           0.0         50  0.66400\n",
      "2   circles           0.0        100  0.66300\n",
      "3   circles           0.0       1000  0.99370\n",
      "4   circles           0.0      10000  1.00000\n",
      "5   circles           0.1         10  0.67000\n",
      "6   circles           0.1         50  0.58600\n",
      "7   circles           0.1        100  0.55500\n",
      "8   circles           0.1       1000  0.81770\n",
      "9   circles           0.1      10000  0.82641\n",
      "10  circles           0.2         10  0.53000\n",
      "11  circles           0.2         50  0.55800\n",
      "12  circles           0.2        100  0.53200\n",
      "13  circles           0.2       1000  0.66090\n",
      "14  circles           0.2      10000  0.66149\n",
      "15  circles           0.3         10  0.62000\n",
      "16  circles           0.3         50  0.48800\n",
      "17  circles           0.3        100  0.49800\n",
      "18  circles           0.3       1000  0.59730\n",
      "19  circles           0.3      10000  0.59576\n",
      "20  circles           0.4         10  0.08000\n",
      "21  circles           0.4         50  0.58800\n",
      "22  circles           0.4        100  0.55800\n",
      "23  circles           0.4       1000  0.57510\n",
      "24  circles           0.4      10000  0.56268\n",
      "25  circles           0.5         10  0.67000\n",
      "26  circles           0.5         50  0.51800\n",
      "27  circles           0.5        100  0.53600\n",
      "28  circles           0.5       1000  0.54490\n",
      "29  circles           0.5      10000  0.53990\n",
      "30    moons           0.0         10  0.25000\n",
      "31    moons           0.0         50  0.90600\n",
      "32    moons           0.0        100  0.92200\n",
      "33    moons           0.0       1000  1.00000\n",
      "34    moons           0.0      10000  1.00000\n",
      "35    moons           0.1         10  0.71000\n",
      "36    moons           0.1         50  0.90000\n",
      "37    moons           0.1        100  0.90200\n",
      "38    moons           0.1       1000  0.99800\n",
      "39    moons           0.1      10000  0.99882\n",
      "40    moons           0.2         10  0.73000\n",
      "41    moons           0.2         50  0.87800\n",
      "42    moons           0.2        100  0.90400\n",
      "43    moons           0.2       1000  0.96890\n",
      "44    moons           0.2      10000  0.96574\n",
      "45    moons           0.3         10  0.63000\n",
      "46    moons           0.3         50  0.84000\n",
      "47    moons           0.3        100  0.88700\n",
      "48    moons           0.3       1000  0.89040\n",
      "49    moons           0.3      10000  0.90289\n",
      "50    moons           0.4         10  0.72000\n",
      "51    moons           0.4         50  0.73200\n",
      "52    moons           0.4        100  0.72800\n",
      "53    moons           0.4       1000  0.84590\n",
      "54    moons           0.4      10000  0.85132\n",
      "55    moons           0.5         10  0.16000\n",
      "56    moons           0.5         50  0.74600\n",
      "57    moons           0.5        100  0.79700\n",
      "58    moons           0.5       1000  0.81280\n",
      "59    moons           0.5      10000  0.80732\n",
      "    ds_type  noise_levels  optimalresults  number_datapoints\n",
      "0   circles           0.0         1.00000            10000.0\n",
      "1   circles           0.1         0.82641            10000.0\n",
      "2   circles           0.2         0.66149            10000.0\n",
      "3   circles           0.3         0.62000               10.0\n",
      "4   circles           0.4         0.58800               50.0\n",
      "5   circles           0.5         0.67000               10.0\n",
      "6     moons           0.0         1.00000             1000.0\n",
      "7     moons           0.1         0.99882            10000.0\n",
      "8     moons           0.2         0.96890             1000.0\n",
      "9     moons           0.3         0.90289            10000.0\n",
      "10    moons           0.4         0.85132            10000.0\n",
      "11    moons           0.5         0.81280             1000.0\n"
     ]
    }
   ],
   "source": [
    "def number_datapoints_optimalresults(df):\n",
    "    # find bast modsel pramter by max teste \n",
    "    # and stabble by std of teste in the difference folds\n",
    "    best_TESTE=df['TESTE'].mean()\n",
    "    return  pd.Series({'valuo':best_TESTE})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def number_datapoints_optimalresults_2(df):\n",
    "    # find bast modsel pramter by max teste \n",
    "    optimalresults=df['valuo'].max()\n",
    "    number_datapoints=df.query('valuo==valuo.max()')[['n_samples']].iloc[0].values[0]\n",
    "    return  pd.Series({'optimalresults':optimalresults,'number_datapoints':number_datapoints})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#6 og_reg\n",
    "data=log_reg_df\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "#type_data_grop=data.groupby(by=['ds_type','noise_levels','n_samples','regularization_value'])['TESTE'].max()\n",
    "type_data_grop=data.groupby(by=['ds_type','noise_levels','n_samples']).apply(lambda df:  number_datapoints_optimalresults(df))\n",
    "\n",
    "type_data_grop=type_data_grop.reset_index()\n",
    "print(type_data_grop)\n",
    "\n",
    "type_data_grop_2=type_data_grop.groupby(by=['ds_type','noise_levels']).apply(lambda df:  number_datapoints_optimalresults_2(df))\n",
    "\n",
    "type_data_grop_2=type_data_grop_2.reset_index()\n",
    "print(type_data_grop_2)\n",
    "\n",
    "print('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n",
    "\n",
    "#type_data_grop['str_n_samples']=type_data_grop['n_samples'].apply(str)\n",
    "#fig = px.scatter(type_data_grop, x='noise_levels', y='TESTE',color='str_n_samples',facet_row='ds_type',height=600)\n",
    "#fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "#fig.show() \n",
    "\n",
    "#@widgets.interact\n",
    "#def plot_provider_success_rate_per_region(n_samples=type_data_grop.n_samples.unique()):\n",
    "    #data =type_data_grop.loc[type_data_grop['n_samples']==n_samples].reset_index().reset_index()\n",
    "    #fig = px.scatter(data, x='noise_levels', y='TESTE',facet_row='ds_type',height=600)\n",
    "    #fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "   # return  fig\n",
    "    \n",
    "# 6 kkn\n",
    "data=knn_df\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "type_data_grop=data.groupby(by=['ds_type','noise_levels','n_samples']).apply(lambda df:  number_datapoints_optimalresults(df))\n",
    "\n",
    "type_data_grop=type_data_grop.reset_index()\n",
    "print(type_data_grop)\n",
    "\n",
    "type_data_grop_2=type_data_grop.groupby(by=['ds_type','noise_levels']).apply(lambda df:  number_datapoints_optimalresults_2(df))\n",
    "\n",
    "type_data_grop_2=type_data_grop_2.reset_index()\n",
    "print(type_data_grop_2)\n",
    "#type_data_grop=data.groupby(by=['ds_type','noise_levels','n_samples','k'])['TESTE'].mean()\n",
    "#type_data_grop=type_data_grop.reset_index()   \n",
    "#type_data_grop['str_n_samples']=type_data_grop['n_samples'].apply(str)\n",
    "#fig = px.scatter(type_data_grop, x='noise_levels', y='TESTE',color='str_n_samples',facet_row='ds_type',height=600)\n",
    "#fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "#fig.show() \n",
    "\n",
    "#@widgets.interact \n",
    "#def plot_provider_success_rate_per_region(n_samples=type_data_grop.n_samples.unique()):\n",
    "    #data =type_data_grop.loc[type_data_grop['n_samples']==n_samples].reset_index().reset_index()\n",
    "    #fig = px.scatter(data, x='noise_levels', y='TESTE',facet_row='ds_type',height=600)\n",
    "    #fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "    #return  fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55dd716b-2b5b-441e-ab5c-98754ccc005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaa\n"
     ]
    }
   ],
   "source": [
    "print('aaaaaaaaaaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc5d47-a63c-45d6-abc8-77c388edde05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
